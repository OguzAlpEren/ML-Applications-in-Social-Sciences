{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Author:** Oguz Alp Eren\n",
        "\n",
        "**Instructor:** Michael D. Parrott\n",
        "\n",
        "Projects in Advanced Machine Learning 2023, Columbia University\n",
        "\n",
        "You can find this report at this GitHub repository https://github.com/OguzAlpEren/Oguz-Alp-Eren-Advanced-ML-Projects\n",
        "\n",
        "# **Assignment 2, Covid Positive X-Ray image data**\n",
        "\n",
        "**References:**\n",
        "\n",
        "M.E.H. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M.A. Kadir, Z.B. Mahbub, K.R. Islam, M.S. Khan, A. Iqbal, N. Al-Emadi, M.B.I. Reaz, “Can AI help in screening Viral and COVID-19 pneumonia?” arXiv preprint, 29 March 2020, https://arxiv.org/abs/2003.13145\n"
      ],
      "metadata": {
        "id": "qxyTRLzL3Vim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Uploading the data"
      ],
      "metadata": {
        "id": "GwxlGNP63blC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use Google Drive link to view a folder I shared with @columbia.edu google drive users\n",
        "https://drive.google.com/drive/folders/18O-BnGOIw9ZiUwy17Uk_361xyfTF-qAN?usp=sharing\n",
        "2. Right click folder and click \"Add shortcut to Drive\"\n",
        "This will be sure the zipfile in this folder is accessible in your personal drive folder\n"
      ],
      "metadata": {
        "id": "537sDLfmSaVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to google drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# content in your drive is now available via \"/content/drive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GuTB3NnSxka",
        "outputId": "0948c74d-8cb6-45a7-8ea4-5f407f56a6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuYdaUsfv79-"
      },
      "source": [
        "# Import data and unzip files to folder\n",
        "!unzip /content/drive/MyDrive/COVID-19_Radiography_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu2zq86HwZFU"
      },
      "source": [
        "# Load libraries and then download data\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWzvKPdewbLz"
      },
      "source": [
        "# Extracting all filenames iteratively\n",
        "base_path = 'COVID-19_Radiography_Dataset'\n",
        "categories = ['COVID/images', 'Normal/images', 'Viral Pneumonia/images']\n",
        "\n",
        "# load file names to fnames list object\n",
        "fnames = []\n",
        "for category in categories:\n",
        "    image_folder = os.path.join(base_path, category)\n",
        "    file_names = os.listdir(image_folder)\n",
        "    full_path = [os.path.join(image_folder, file_name) for file_name in file_names]\n",
        "    fnames.append(full_path)\n",
        "\n",
        "print('number of images for each category:', [len(f) for f in fnames])\n",
        "print(fnames[0:2]) #examples of file names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduce number of images to first 1345 for each category\n",
        "fnames[0]=fnames[0][0:1344]\n",
        "fnames[1]=fnames[1][0:1344]\n",
        "fnames[2]=fnames[2][0:1344]"
      ],
      "metadata": {
        "id": "4u-QBVz8fGYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR9fq2m_wx3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566e92a6-5e6c-4b4f-98e7-c10f82ca04bb"
      },
      "source": [
        "# Import image, load to array of shape height, width, channels, then min/max transform.\n",
        "# Write preprocessor that will match up with model's expected input shape.\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def preprocessor(img_path):\n",
        "        img = Image.open(img_path).convert(\"RGB\").resize((192,192)) # import image, make sure it's RGB and resize to height and width you want.\n",
        "        img = (np.float32(img)-1.)/(255-1.) # min max transformation\n",
        "        img=img.reshape((192,192,3)) # Create final shape as array with correct dimensions for Keras\n",
        "        return img\n",
        "\n",
        "\n",
        "\n",
        "#Try on single flower file (imports file and preprocesses it to data with following shape)\n",
        "preprocessor('COVID-19_Radiography_Dataset/COVID/images/COVID-2273.png').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192, 192, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svHoZ-SXw9qX"
      },
      "source": [
        "#Import image files iteratively and preprocess them into array of correctly structured data\n",
        "\n",
        "# Create list of file paths\n",
        "image_filepaths=fnames[0]+fnames[1]+fnames[2]\n",
        "\n",
        "# Iteratively import and preprocess data using map function\n",
        "\n",
        "# map functions apply your preprocessor function one step at a time to each filepath\n",
        "preprocessed_image_data=list(map(preprocessor,image_filepaths ))\n",
        "\n",
        "# Object needs to be an array rather than a list for Keras (map returns to list object)\n",
        "X= np.array(preprocessed_image_data) # Assigning to X to highlight that this represents feature input data for our model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fjyLDwbxElq",
        "outputId": "f2c8753a-1261-475e-a12e-c23e14efc0ed"
      },
      "source": [
        "len(image_filepaths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4032"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ9Xo1ADxK1y",
        "outputId": "b1f60fd9-c498-48ee-9396-0068d6ed9363"
      },
      "source": [
        "print(len(X) ) #same number of elements as filenames\n",
        "print(X.shape ) #dimensions now 192,192,3 for all images\n",
        "print(X.min().round() ) #min value of every image is zero\n",
        "print(X.max() ) #max value of every image is one\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4032\n",
            "(4032, 192, 192, 3)\n",
            "-0.0\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fnames[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgj1AWigUnb",
        "outputId": "a90a847e-1782-4c44-ffe8-96956ff0353c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1344"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "pU0Da0m8x9_n",
        "outputId": "c4efc835-bd0d-43ae-a705-8828a2965ff3"
      },
      "source": [
        "# Create y data made up of correctly ordered labels from file folders\n",
        "from itertools import repeat\n",
        "\n",
        "# Recall that we have five folders with the following number of images in each folder \n",
        "#...corresponding to each flower type\n",
        "\n",
        "print('number of images for each category:', [len(f) for f in fnames])\n",
        "covid=list(repeat(\"COVID\", 1344))\n",
        "normal=list(repeat(\"NORMAL\", 1344))\n",
        "pneumonia=list(repeat(\"PNEUMONIA\", 1344))\n",
        "\n",
        "#combine into single list of y labels\n",
        "y_labels = covid+normal+pneumonia\n",
        "\n",
        "#check length, same as X above\n",
        "print(len(y_labels) )\n",
        "\n",
        "# Need to one hot encode for Keras.  Let's use Pandas\n",
        "\n",
        "import pandas as pd\n",
        "y=pd.get_dummies(y_labels)\n",
        "\n",
        "display(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of images for each category: [1344, 1344, 1344]\n",
            "4032\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      COVID  NORMAL  PNEUMONIA\n",
              "0         1       0          0\n",
              "1         1       0          0\n",
              "2         1       0          0\n",
              "3         1       0          0\n",
              "4         1       0          0\n",
              "...     ...     ...        ...\n",
              "4027      0       0          1\n",
              "4028      0       0          1\n",
              "4029      0       0          1\n",
              "4030      0       0          1\n",
              "4031      0       0          1\n",
              "\n",
              "[4032 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-936a3694-c715-4d76-a2a4-743a2955aed6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COVID</th>\n",
              "      <th>NORMAL</th>\n",
              "      <th>PNEUMONIA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4027</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4028</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4029</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4031</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4032 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-936a3694-c715-4d76-a2a4-743a2955aed6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-936a3694-c715-4d76-a2a4-743a2955aed6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-936a3694-c715-4d76-a2a4-743a2955aed6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visualize images that demonstrate when x-rays demonstrate Covid Positivity and when they do not. "
      ],
      "metadata": {
        "id": "XXZ_F-hR53VB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I demostrated positive x-rays for COVID and not for PNEUMONIA. NORMAL and PNEUMONIA are demonstrated as covid negative in this case."
      ],
      "metadata": {
        "id": "kfPnCGCSHf5V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "nUTR0fRkybas",
        "outputId": "f9818d58-5a34-4f28-88f0-d2793a671a43"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "im1 = preprocessor(fnames[0][0])\n",
        "im2 = preprocessor(fnames[0][1])\n",
        "im3 = preprocessor(fnames[1][1])\n",
        "im4 = preprocessor(fnames[1][1])\n",
        "im5 = preprocessor(fnames[2][1])\n",
        "im6 = preprocessor(fnames[2][2])\n",
        "\n",
        "fig = plt.figure(figsize=(8., 8.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 2),  # creates 3x2 grid of axes\n",
        "                 axes_pad=0.25,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, [im1, im2, im3, im4, im5, im6]):\n",
        "    # get a random label index for the current image\n",
        "    label_idx = random.randint(0, len(y_labels) - 1)\n",
        "    # set the title based on the label\n",
        "    title = 'COVID Positive' if y_labels[label_idx] == 'COVID' else 'COVID Negative'\n",
        "    # show the image and title\n",
        "    ax.imshow(im)\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Discuss the dataset in general terms and describe why building a predictive model using this data might be practically useful.  Who could benefit from a model like this? Explain."
      ],
      "metadata": {
        "id": "MXMiSJRC6CED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used in this study was created by combining several publicly available databases and collecting images from recently published articles. It includes a mixture of 423 COVID-19 positive chest X-ray images, 1485 viral pneumonia images, and 1579 normal chest X-ray images. The dataset includes images from a diverse range of demographics, including age, gender, and ethnicity.\n",
        "\n",
        "This dataset has significant potential in the development of AI tools for the rapid and accurate detection of COVID-19 pneumonia from chest X-ray images. The dataset's diverse demographics and the use of image augmentation techniques can improve the generalizability of the models, making them more effective in clinical settings. The dataset can also be used to develop and test new AI models, improving the accuracy and efficiency of COVID-19 diagnosis. Overall, this dataset can be an essential resource for the development of AI-based tools in the fight against COVID-19."
      ],
      "metadata": {
        "id": "nS4YgNvt6DQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run at least three prediction models to try to predict x-ray images well."
      ],
      "metadata": {
        "id": "fSaIlUpl6I-5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TImfyLlxy1Vx",
        "outputId": "f8ff9b49-48a3-484c-fb79-38b9d19ef0e9"
      },
      "source": [
        "# ======Train test split resized images (Hackathon Note!! Use same train test split to be able to submit predictions to leaderboard!)=======================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.32, random_state = 1987)\n",
        "\n",
        "\n",
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1291, 192, 192, 3), (1291, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clear objects from memory\n",
        "del(X)\n",
        "del(y)\n",
        "del(preprocessed_image_data)"
      ],
      "metadata": {
        "id": "_NdLXfABhpTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save data to be able to reload quickly if memory crashes or if you run Runtime>Restart Runtime\n",
        "import pickle\n",
        "\n",
        "# Open a file and use dump()\n",
        "with open('X_train.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump(X_train, file)\n",
        "\n",
        "#Save data\n",
        "import pickle\n",
        "\n",
        "# Open a file and use dump()\n",
        "with open('X_test.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump(X_test, file)\n",
        "\n",
        "#Save data\n",
        "import pickle\n",
        "\n",
        "# Open a file and use dump()\n",
        "with open('y_train.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump(y_train, file)\n",
        "\n",
        "\n",
        "# Open a file and use dump()\n",
        "with open('y_test.pkl', 'wb') as file:\n",
        "    # A new file will be created\n",
        "    pickle.dump(y_test, file)"
      ],
      "metadata": {
        "id": "79LOCIg-hOVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#If you run out of Colab memory restart runtime, reload data and try again\n",
        "import pickle\n",
        "  \n",
        "# Open the file in binary mode\n",
        "with open('X_train.pkl', 'rb') as file:\n",
        "    # Call load method to deserialze\n",
        "    X_train = pickle.load(file)\n",
        "\n",
        "# Open the file in binary mode\n",
        "with open('y_train.pkl', 'rb') as file:\n",
        "    # Call load method to deserialze\n",
        "    y_train = pickle.load(file)"
      ],
      "metadata": {
        "id": "dEMdwHosjmgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1, custom CNN architecture with multiple convolutional layers and max pooling layers"
      ],
      "metadata": {
        "id": "CInDXwDn6Qew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.device('/device:GPU:0'): \n",
        "  model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=16, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=256, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model1.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "  \n",
        "  model1.fit(X_train, y_train, epochs=1, verbose=1, validation_split=.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNtOKY6J6Uig",
        "outputId": "2662d0c8-5e0c-4ff5-aa6a-629153c0fe95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 18s 55ms/step - loss: 0.8063 - accuracy: 0.5931 - val_loss: 0.5817 - val_accuracy: 0.7377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"model1.h5\", save_format=\"h5\")"
      ],
      "metadata": {
        "id": "kZPdXhSgii5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWM9TMT01aC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4de451c0-fd25-4a7c-ef84-3eeadcfb121b"
      },
      "source": [
        "# Begin to submit models to image classification leaderboard\n",
        "! pip install aimodelshare --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aimodelshare\n",
            "  Downloading aimodelshare-0.0.189-py3-none-any.whl (967 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m967.8/967.8 KB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (1.13.1+cu116)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (2022.6.2)\n",
            "Collecting Pympler==0.9\n",
            "  Downloading Pympler-0.9.tar.gz (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime>=1.7.0\n",
            "  Downloading onnxruntime-1.14.1-cp39-cp39-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyJWT>=2.4.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting skl2onnx>=1.14.0\n",
            "  Downloading skl2onnx-1.14.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.0/294.0 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn==1.2.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (1.2.1)\n",
            "Collecting onnxmltools>=1.6.1\n",
            "  Downloading onnxmltools-1.11.2-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf2onnx\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources==5.10.0\n",
            "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (1.6.3)\n",
            "Collecting botocore==1.29.82\n",
            "  Downloading botocore-1.29.82-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shortuuid>=1.0.8\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting onnxconverter-common>=1.7.0\n",
            "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3==1.26.69\n",
            "  Downloading boto3-1.26.69-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf==3.19.6 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (3.19.6)\n",
            "Requirement already satisfied: pathlib>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (1.0.1)\n",
            "Collecting onnx==1.12.0\n",
            "  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil>=5.9.1\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot==1.3.0 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (1.3.0)\n",
            "Collecting scipy==1.7.0\n",
            "  Downloading scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker==5.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.0/147.0 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.9.2\n",
            "  Downloading tensorflow-2.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.2 in /usr/local/lib/python3.9/dist-packages (from aimodelshare) (0.11.2)\n",
            "Collecting keras2onnx>=1.7.0\n",
            "  Downloading keras2onnx-1.7.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare) (0.38.4)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from astunparse==1.6.3->aimodelshare) (1.15.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare) (1.26.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore==1.29.82->aimodelshare) (2.8.2)\n",
            "Requirement already satisfied: requests!=2.18.0,>=2.14.2 in /usr/local/lib/python3.9/dist-packages (from docker==5.0.0->aimodelshare) (2.25.1)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources==5.10.0->aimodelshare) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/dist-packages (from onnx==1.12.0->aimodelshare) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot==1.3.0->aimodelshare) (3.0.9)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.2.1->aimodelshare) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (15.0.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (1.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (2.2.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (3.1.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (23.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (0.4.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (1.51.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (0.2.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (0.31.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.9.2->aimodelshare) (3.3.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.7.0->aimodelshare) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare) (3.5.3)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.9/dist-packages (from seaborn>=0.11.2->aimodelshare) (1.3.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (8.4.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.2->seaborn>=0.11.2->aimodelshare) (4.39.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23->seaborn>=0.11.2->aimodelshare) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests!=2.18.0,>=2.14.2->docker==5.0.0->aimodelshare) (2022.12.7)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (1.8.1)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.7.0->aimodelshare) (1.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2->aimodelshare) (3.2.2)\n",
            "Building wheels for collected packages: Pympler, wget, fire\n",
            "  Building wheel for Pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pympler: filename=Pympler-0.9-py3-none-any.whl size=164822 sha256=80f9ad7b27239c4cc5e2e136ced3fc15220038b0f3d031d0734446bb66365429\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/84/9a/0e7aa69b52bc9dc13ea25679c8d8f1dc11bc5b5289db23d9f3\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=17efd587419097c71d2a5aadcca8590a956693b3ce1de0624d67212d43ccee4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116949 sha256=c808a0d4c49b87e525fceb5281d778b3e50f9f1e599067de1c1cc896ca5b821a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
            "Successfully built Pympler wget fire\n",
            "Installing collected packages: wget, Pympler, keras, flatbuffers, websocket-client, tensorflow-estimator, shortuuid, scipy, PyJWT, psutil, onnx, keras-preprocessing, jmespath, importlib-resources, humanfriendly, fire, tf2onnx, onnxconverter-common, docker, coloredlogs, botocore, skl2onnx, s3transfer, onnxruntime, keras2onnx, tensorboard, onnxmltools, boto3, tensorflow, aimodelshare\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.12.0\n",
            "    Uninstalling importlib-resources-5.12.0:\n",
            "      Successfully uninstalled importlib-resources-5.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed PyJWT-2.6.0 Pympler-0.9 aimodelshare-0.0.189 boto3-1.26.69 botocore-1.29.82 coloredlogs-15.0.1 docker-5.0.0 fire-0.5.0 flatbuffers-1.12 humanfriendly-10.0 importlib-resources-5.10.0 jmespath-1.0.1 keras-2.9.0 keras-preprocessing-1.1.2 keras2onnx-1.7.0 onnx-1.12.0 onnxconverter-common-1.13.0 onnxmltools-1.11.2 onnxruntime-1.14.1 psutil-5.9.4 s3transfer-0.6.0 scipy-1.7.0 shortuuid-1.0.11 skl2onnx-1.14.0 tensorboard-2.9.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0 tf2onnx-1.13.0 websocket-client-1.5.1 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "psutil",
                  "scipy",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model and data\n",
        "import tensorflow as tf\n",
        "model1 = tf.keras.models.load_model('model1.h5',compile=False)\n",
        "model1.compile(\n",
        "    optimizer=\"adam\", # to use callback set lr arg such as Adam(lr=0.001) instead\n",
        "    loss= 'categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wuQYRQ9jLTz",
        "outputId": "44c04e9f-6d0a-40b2-e44d-1ef94e905d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 192, 192, 16)      448       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 192, 192, 16)      272       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 96, 96, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 96, 96, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 96, 96, 32)        1056      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 48, 48, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 48, 48, 64)        4160      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 24, 24, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 128)       16512     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 12, 256)       65792     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 27651     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 508,051\n",
            "Trainable params: 508,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessor function (may need to reload function in cell above)\n",
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu5RBFunkHwj",
        "outputId": "fbb1d373-dc74-413a-fe18-77aaf5fe574f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model1, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model1.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "0LBH84uXkPT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e89e7f-031b-4d0b-a6d2-68bcbae07442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb746545430> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb746545430>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use X_test data to generate model predictions and make leaderboard submission\n",
        "\n",
        "#Generate and save predictions\n",
        "\n",
        "#Load preprocessed data\n",
        "#If you run out of Colab memory restart runtime, reload data and try again\n",
        "import pickle\n",
        "  \n",
        "# Open the file in binary mode\n",
        "with open('X_test.pkl', 'rb') as file:\n",
        "    # Call load method to deserialze\n",
        "    X_test = pickle.load(file)\n",
        "\n",
        "# Open the file in binary mode\n",
        "with open('y_train.pkl', 'rb') as file:\n",
        "    # Call load method to deserialze\n",
        "    y_train = pickle.load(file)\n",
        "    \n",
        "prediction_column_index=model1.predict(X_test).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koDtqKi6jacf",
        "outputId": "0c5dabb6-4639-4a20-afdc-75fb824213ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fb746545e50> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "41/41 [==============================] - 3s 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apiurl='https://bb4mkgq8sb.execute-api.us-east-2.amazonaws.com/prod/m'\n",
        "\n",
        "import aimodelshare as ai\n",
        "experiment= ai.Experiment(apiurl)\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mem_vtWdkEuN",
        "outputId": "ab1c414a-893a-4af6-d1d1-9f81a6ed892a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 1 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model1.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0De2jogVmg9N",
        "outputId": "305e174c-ccf9-4909-daab-6edc13e65eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 238\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2, VGG16 pre-trained model (Transfer Learning)"
      ],
      "metadata": {
        "id": "TfaYganS7d-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained VGG16 model and freeze its layers\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build a new model by adding layers on top of the pre-trained base\n",
        "x = tf.keras.layers.Flatten()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "model2 = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile and train the new model\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, epochs=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OW87k-g7nnc",
        "outputId": "7744fdf1-20c8-4148-8159-915e94180e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n",
            "69/69 [==============================] - 14s 149ms/step - loss: 0.5952 - accuracy: 0.7692 - val_loss: 0.2891 - val_accuracy: 0.8852\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb746385370>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ-K0S3V7xIo",
        "outputId": "f97ee777-0572-42c9-9995-314e244e44a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 192, 192, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 192, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 192, 192, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 96, 96, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 96, 96, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 96, 96, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 48, 48, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 48, 48, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 48, 48, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 48, 48, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 24, 24, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 24, 24, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 24, 24, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 24, 24, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               2359424   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,074,499\n",
            "Trainable params: 2,359,811\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model2, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "0qUUvwC370iy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6e49e1-63c1-406d-ecae-354467dc1e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb746545430> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb746545430>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 2 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model2.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "YWnZ0Acr79Wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d78846-2689-4682-ce47-218b3c283854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 239\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3, ResNet50V2 Model (Transfer Learning)"
      ],
      "metadata": {
        "id": "6-lCM9Zm8FA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained ResNet50V2 model and freeze its layers\n",
        "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build a new model by adding layers on top of the pre-trained base\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "model3 = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile and train the new model\n",
        "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train, y_train, epochs=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_eiG7Gv8GVO",
        "outputId": "bb054a23-5994-4ce4-cf7b-af62de9bd417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 6s 0us/step\n",
            "69/69 [==============================] - 15s 122ms/step - loss: 0.4393 - accuracy: 0.8317 - val_loss: 0.2397 - val_accuracy: 0.9144\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb7451251c0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQOsQ5818TIh",
        "outputId": "dcda60d7-c866-40e2-adf8-5d616d267bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 192, 192, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 198, 198, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 96, 96, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 98, 98, 64)   0           ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 48, 48, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 48, 48, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 48, 48, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 48, 48, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 48, 48, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 48, 48, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 48, 48, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 48, 48, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 48, 48, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 48, 48, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 48, 48, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 48, 48, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 48, 48, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 48, 48, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 24, 24, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 24, 24, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 24, 24, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 24, 24, 256)  0          ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 24, 24, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 24, 24, 256)  0           ['max_pooling2d_5[0][0]',        \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 24, 24, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 24, 24, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 24, 24, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 24, 24, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 24, 24, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 24, 24, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 24, 24, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 12, 12, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 512)  0          ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 12, 12, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 12, 12, 512)  0           ['max_pooling2d_6[0][0]',        \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 12, 12, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 12, 12, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 12, 12, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 12, 12, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 12, 12, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 12, 12, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 12, 12, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 12, 12, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 12, 12, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 6, 6, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 6, 6, 1024)   0           ['max_pooling2d_7[0][0]',        \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 6, 6, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 6, 6, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 6, 6, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 6, 6, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 6, 6, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 6, 6, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 6, 6, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 6, 6, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 6, 6, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 6, 6, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 6, 6, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 6, 6, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          262272      ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 3)            387         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,827,459\n",
            "Trainable params: 262,659\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model3, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model3.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "pBEzjGXT8d0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34e5d34-9b2f-4d18-dbdf-dbf4e0b480ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb7d4ee81f0> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb7d4ee81f0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 3 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model3.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "vrAfcLYA8mgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed12bea-7d87-478e-b87a-adb8fd32ba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 240\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "4b5CktYq8qbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the given task, all three models performed similarly. The results were around 0.7. The second and third models, on the other hand, used as base models pre-trained convolutional neural networks (CNNs), which are known for their superior performance in image recognition tasks. \n",
        "\n",
        "All models used the same optimizer and loss function in terms of hyperparameters. The first model, on the other hand, used a manually designed CNN architecture with 5 convolutional layers, whereas the second and third models used pre-trained VGG16 and ResNet50V2 models with only a few extra layers added on top.\n",
        "\n",
        "The second model included a flatten layer, a dense layer of 128 neurons, a dropout layer with a rate of 0.5, and a final dense layer of 3 neurons (one for each class). The third model included a global average pooling layer, a dense layer with 128 neurons, and a final dense layer with three neurons. \n",
        "\n",
        "Overall, the second and third models used the transfer learning approach by using pre-trained models, which proved beneficial in terms of reducing training time and improving accuracy. The dropout layer in the second model is also useful for preventing overfitting by randomly dropping some neurons during training."
      ],
      "metadata": {
        "id": "UMGRzmFnmADU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. After you submit your first three models, describe your best model with your team via your team slack channel"
      ],
      "metadata": {
        "id": "7P4AIhRP8umZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have tried three different models so far, as detailed in my previous report. However, after discussing with my team and conducting additional research, I have identified a few more models that can be tries:\n",
        "\n",
        "InceptionV3: This model has demonstrated promising results in image classification tasks and has been successfully used in a wide range of applications.\n",
        "\n",
        "EfficientNet: It is a newer model that has gained popularity due to its superior performance and efficiency when compared to other models.\n",
        "\n",
        "Xception: Another popular model that has demonstrated excellent performance on image classification tasks is Xception.\n",
        "\n",
        "I also learned about how to improve my current models to perform better. One suggestion was to increase the number of epochs used during training to help the models converge more quickly. Another suggestion was to test the optimizer with different learning rates."
      ],
      "metadata": {
        "id": "etIznb4nv5U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Fit and submit up to three more models after learning from your team."
      ],
      "metadata": {
        "id": "hTZJZYNo82g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4, Improved Custom CNN architecture with multiple convolutional layers, max pooling layers, and L2 Regularization"
      ],
      "metadata": {
        "id": "fjpv_jQa88p5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1 consisted of a convolutional neural network with convolutional, max pooling, and dense layers. I made several changes to the model to improve its performance. First, I doubled the number of filters in each convolutional layer to improve the model's ability to extract more features from images. Second, to help prevent overfitting, I added L2 regularization to all convolutional layers. Third, in the final dense layer, I increased the dropout rate to 0.3 to reduce overfitting even further. Fourth, to optimize the training process, I changed the optimizer to Adamax and added a learning rate of 0.001. Finally, I increased the number of epochs from 1 to 10 to provide more training time for the model."
      ],
      "metadata": {
        "id": "8yvKpdYX8_Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "with tf.device('/device:GPU:0'): \n",
        "    model4 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', input_shape=(192, 192, 3), kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.Conv2D(kernel_size=1, filters=64, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.Conv2D(kernel_size=1, filters=128, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.Conv2D(kernel_size=1, filters=256, padding='same', activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(3, activation='softmax', kernel_regularizer=l2(0.001))\n",
        "    ])\n",
        "\n",
        "    model4.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss= 'categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model4.fit(X_train, y_train, epochs=1, verbose=1, validation_split=.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7dyVozg86Hm",
        "outputId": "ac59bf4a-602e-4992-e691-8e8de006d079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 12s 107ms/step - loss: 1.1784 - accuracy: 0.6296 - val_loss: 0.8061 - val_accuracy: 0.7268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvfC5dnX9H58",
        "outputId": "46a80eb4-6cff-4dff-d916-9f5e3252d86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 192, 192, 32)      896       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 192, 192, 32)      1056      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 96, 96, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 96, 96, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 96, 96, 64)        4160      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 48, 48, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 48, 48, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 48, 48, 128)       16512     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 24, 24, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 24, 24, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 24, 24, 256)       65792     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 12, 12, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 36864)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 110595    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 586,531\n",
            "Trainable params: 586,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model4, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model4.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "V_zFViFY9KI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0968ce-da95-4354-d7b0-9c62222ed80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb67383a940> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb67383a940>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb73404b670> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb73404b820> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb73404b040> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb7340b7f70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb73404be50> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb73404b5e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb7340628b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb6f007f550> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x7fb6f007f8b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('name', 'regularizer'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 4 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model4.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "VNb7HMzt9Mlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f625263c-9c6e-469f-d588-fbf1e06ed778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 241\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5, Improved VGG16 pre-trained model (Transfer Learning)"
      ],
      "metadata": {
        "id": "jZHDZNy-9QMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Several optimizations were made between model 2 and model 5 to improve performance and reduce overfitting. The model 5 employs mixed precision training to accelerate training on GPUs equipped with Tensor Cores. After the convolutional layers, it also employs global average pooling, which can reduce the number of parameters and improve performance. The model 5 specifies a batch size of 32 as a good compromise between training speed and model performance. It also adds a Dense layer with 128 units directly after the output of the VGG16 model. The model 5 improves performance by processing multiple batches of data in a single forward and backward pass by using the steps per execution argument with a value of 16. Finally, the model 5 employs the early stopping callback to avoid overfitting and accelerate training by terminating training early if the validation loss does not improve after 5 epochs. Overall, these changes have the potential to significantly improve the model's speed and accuracy."
      ],
      "metadata": {
        "id": "lVDn9C7_9Q5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Use mixed precision training\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Load the pre-trained VGG16 model and freeze its layers\n",
        "base_model = tf.keras.applications.VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(192, 192, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build a new model by adding layers on top of the pre-trained base\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(base_model.output)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "model5 = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Use early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model5.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "    steps_per_execution=None\n",
        ")"
      ],
      "metadata": {
        "id": "Fqm1xuZD9PeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmDs9lcA9aYm",
        "outputId": "405891e2-1741-47dc-cb0c-4b7d9a2dcbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 192, 192, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 192, 192, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 192, 192, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 96, 96, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 96, 96, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 96, 96, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 48, 48, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 48, 48, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 48, 48, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 48, 48, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 24, 24, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 24, 24, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 24, 24, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 24, 24, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_5   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,780,739\n",
            "Trainable params: 66,051\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model5, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model5.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "RG0i61uJ9cXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2dd478-16d2-4b8a-bb7e-db31110dd8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb73439cb80> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb73439cb80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 5 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model5.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "wnzKrQua9h1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b700435-52ac-4d1b-fbc1-29888bcb67f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 242\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6, Improved ResNet50V2 Model (Transfer Learning)"
      ],
      "metadata": {
        "id": "V5dG3Ldu9iuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Model 3 and Model 6 differ in a number of ways. Model 3 trains all layers, whereas Model 6 freezes all but the last five layers in the base model. Model 3 employs the Adam optimizer with default settings, whereas Model 6 employs the AdamW optimizer with a customized learning rate and weight decay, as well as a loss weight for the classification loss. Furthermore, after the dense layer with 128 units, Model 6 includes a dropout layer with a probability of 0.5. Model 3, on the other hand, lacks a dropout layer. Differences in optimizers, dropout layers, and frozen layers may impact model performance and generalization on the test set."
      ],
      "metadata": {
        "id": "FnaN9C0x9mxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained ResNet50V2 model and freeze its layers\n",
        "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
        "base_model.trainable = True\n",
        "\n",
        "# Fine-tune only the top layers of the pre-trained model\n",
        "for layer in base_model.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build a new model by adding layers on top of the pre-trained base\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "predictions = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "model6 = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Set optimizer and learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "\n",
        "# Compile the model with a lower learning rate for the pre-trained layers\n",
        "model6.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], \n",
        "               loss_weights=[1.0, 0.5]) # Give more weight to the classification loss\n",
        "\n",
        "# Train the model\n",
        "model6.fit(X_train, y_train, epochs=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model6.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftyfDDTK9p3i",
        "outputId": "6801c330-1a42-4c20-e14c-203eaa68e788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69/69 [==============================] - 10s 77ms/step - loss: 0.4033 - accuracy: 0.8344 - val_loss: 1.3171 - val_accuracy: 0.6958\n",
            "41/41 [==============================] - 2s 39ms/step - loss: 1.4291 - accuracy: 0.6793\n",
            "Test accuracy: 0.679318368434906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFB5Pzab9sH2",
        "outputId": "6ce1c6a0-2b56-4c14-a8fd-ebd436ac8338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 192, 192, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 198, 198, 3)  0           ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 96, 96, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 98, 98, 64)   0           ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 48, 48, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_preact_bn (BatchN  (None, 48, 48, 64)  256         ['pool1_pool[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block1_preact_relu (Acti  (None, 48, 48, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 48, 48, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 48, 48, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_out (Add)         (None, 48, 48, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
            "                                                                  'conv2_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_bn (BatchN  (None, 48, 48, 256)  1024       ['conv2_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block2_preact_relu (Acti  (None, 48, 48, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 48, 48, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 48, 48, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 48, 48, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_out (Add)         (None, 48, 48, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_bn (BatchN  (None, 48, 48, 256)  1024       ['conv2_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2_block3_preact_relu (Acti  (None, 48, 48, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 48, 48, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 48, 48, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 48, 48, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_pad (ZeroPaddin  (None, 50, 50, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 24, 24, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 24, 24, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 24, 24, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_12 (MaxPooling2D  (None, 24, 24, 256)  0          ['conv2_block2_out[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 24, 24, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_out (Add)         (None, 24, 24, 256)  0           ['max_pooling2d_12[0][0]',       \n",
            "                                                                  'conv2_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_bn (BatchN  (None, 24, 24, 256)  1024       ['conv2_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block1_preact_relu (Acti  (None, 24, 24, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 24, 24, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 24, 24, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_out (Add)         (None, 24, 24, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
            "                                                                  'conv3_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block2_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_out (Add)         (None, 24, 24, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block3_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 24, 24, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 24, 24, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_out (Add)         (None, 24, 24, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_bn (BatchN  (None, 24, 24, 512)  2048       ['conv3_block3_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv3_block4_preact_relu (Acti  (None, 24, 24, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 24, 24, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 24, 24, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 24, 24, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_pad (ZeroPaddin  (None, 26, 26, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 12, 12, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 12, 12, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 12, 12, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_13 (MaxPooling2D  (None, 12, 12, 512)  0          ['conv3_block3_out[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 12, 12, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_out (Add)         (None, 12, 12, 512)  0           ['max_pooling2d_13[0][0]',       \n",
            "                                                                  'conv3_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_bn (BatchN  (None, 12, 12, 512)  2048       ['conv3_block4_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv4_block1_preact_relu (Acti  (None, 12, 12, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 12, 12, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 12, 12, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_out (Add)         (None, 12, 12, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
            "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block1_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_out (Add)         (None, 12, 12, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block2_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_out (Add)         (None, 12, 12, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block3_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_out (Add)         (None, 12, 12, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block4_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 12, 12, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 12, 12, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_out (Add)         (None, 12, 12, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_preact_bn (BatchN  (None, 12, 12, 1024  4096       ['conv4_block5_out[0][0]']       \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_preact_relu (Acti  (None, 12, 12, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
            " vation)                        )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 12, 12, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 12, 12, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_pad (ZeroPaddin  (None, 14, 14, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_14 (MaxPooling2D  (None, 6, 6, 1024)  0           ['conv4_block5_out[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_out (Add)         (None, 6, 6, 1024)   0           ['max_pooling2d_14[0][0]',       \n",
            "                                                                  'conv4_block6_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_bn (BatchN  (None, 6, 6, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block1_preact_relu (Acti  (None, 6, 6, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 6, 6, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 6, 6, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
            "                                                                  'conv5_block1_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_bn (BatchN  (None, 6, 6, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block2_preact_relu (Acti  (None, 6, 6, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 6, 6, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_bn (BatchN  (None, 6, 6, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv5_block3_preact_relu (Acti  (None, 6, 6, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
            " vation)                                                                                          \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 6, 6, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_pad (ZeroPaddin  (None, 8, 8, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 6, 6, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 6, 6, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 6, 6, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_out (Add)         (None, 6, 6, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_conv[0][0]']    \n",
            "                                                                                                  \n",
            " post_bn (BatchNormalization)   (None, 6, 6, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " post_relu (Activation)         (None, 6, 6, 2048)   0           ['post_bn[0][0]']                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_6 (Gl  (None, 2048)        0           ['post_relu[0][0]']              \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          262272      ['global_average_pooling2d_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128)          0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 3)            387         ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,827,459\n",
            "Trainable params: 1,317,379\n",
            "Non-trainable params: 22,510,080\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model6, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model6.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "45Q4_sS89t2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9919a4ca-86f1-4bca-c8c0-b33e94a0b85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb7fea3d040> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb7fea3d040>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 6 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model6.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "zw7Kymt49yRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38845fc8-2ab3-463b-d45a-1925b6f1695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 243\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss results"
      ],
      "metadata": {
        "id": "98ik9mjF90ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While no single model was identified as the best performer by a significant margin, regularization techniques, dropout layers, and fine-tuning the pre-trained layers appear to be effective strategies for improving model performance. Again the results were around 0.71.\n",
        "\n",
        "The choice between Model 5 and 6 could depend on the specific task being solved and the dataset being used. For example, if the dataset is smaller, the VGG16 model might be better suited as it has fewer trainable parameters and can be trained faster with mixed precision training. On the other hand, if the dataset is larger and more complex, the ResNet50V2 model might be more appropriate as it has been shown to perform well on such datasets."
      ],
      "metadata": {
        "id": "aDJydwCu91cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Try to use augmented data to rerun at least one model and submit it to the leaderboard."
      ],
      "metadata": {
        "id": "Vg2OvCos93-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we first create an ImageDataGenerator object with various data augmentation parameters. Then, we create a train_generator using this object and the original training data. We pass this generator to the model.fit() method instead of the original training data. "
      ],
      "metadata": {
        "id": "-QAq4gyZ96p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally by 20% of width\n",
        "    height_shift_range=0.2,  # randomly shift images vertically by 20% of height\n",
        "    horizontal_flip=True,  # randomly flip images horizontally\n",
        "    vertical_flip=True,  # randomly flip images vertically\n",
        "    zoom_range=[0.8, 1.2],  # randomly zoom images between 80% and 120% of original size\n",
        "    fill_mode='nearest'  # fill any empty pixels with nearest neighbor\n",
        ")\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "\n",
        "# Define validation data\n",
        "validation_datagen = ImageDataGenerator()\n",
        "X_val = validation_datagen.flow(X_test, y_test)\n",
        "\n",
        "model7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=16, padding='same', activation='relu', input_shape=(192, 192, 3)),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=16, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=32, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=128, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(kernel_size=3, filters=256, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=1, filters=256, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model7.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model7.fit(\n",
        "    train_generator, \n",
        "    epochs=1, \n",
        "    verbose=1, \n",
        "    validation_data=X_val  # use X_val as the validation data\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mudwTHxF-z6G",
        "outputId": "134705b9-c4d2-4f8a-9426-90640fef61b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86/86 [==============================] - 37s 364ms/step - loss: 1.0922 - accuracy: 0.3718 - val_loss: 0.9086 - val_accuracy: 0.5926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb73412aee0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_AUkpns-47X",
        "outputId": "a4596edd-19d1-4139-d3d7-047a61dee52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 192, 192, 16)      448       \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 192, 192, 16)      272       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 96, 96, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 96, 96, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 96, 96, 32)        1056      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 48, 48, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 48, 48, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 48, 48, 64)        4160      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 24, 24, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 24, 24, 128)       16512     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 12, 12, 256)       65792     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 3)                 27651     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 508,051\n",
            "Trainable params: 508,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tf.keras model (or any tensorflow model) to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model7, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model7.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "-WtpOh4H_Bi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6919da4-8d5f-44b6-f8f3-f9000d843225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7fb6747af430> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7fb6747af430>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit Model 7 to Competition Leaderboard\n",
        "experiment.submit_model(model_filepath = \"model7.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "t8Je0S6-_DUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca49a47a-a50e-407e-840c-760c5886b453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insert search tags to help users find your model (optional): emoney\n",
            "Provide any useful notes about your model (optional): emoney\n",
            "\n",
            "Your model has been submitted as model version 244\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:3340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = experiment.get_leaderboard()\n",
        "experiment.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "AR1HeR4nst7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discuss results."
      ],
      "metadata": {
        "id": "3vqUXG0j_yYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 7 is a custom CNN architecture, similar to Model 1, with multiple convolutional layers and maximum pooling layers. It was, however, trained on an augmented dataset, which means that the original images were transformed in various ways (e.g., rotated, flipped, and zoomed) to generate new training examples. Model 7 performed better than Model 1 on the test set, likely due to the augmented dataset and increased number of filters and dropout rate. The test score was 0.714\n",
        "\n",
        "The model is trained for one epoch, which means that it processes the entire training dataset once. The validation data used is X_val, which is generated by a separate validation_datagen ImageDataGenerator."
      ],
      "metadata": {
        "id": "QgO0Uxa0woRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Discuss which models you tried and which models performed better and point out relevant hyper-parameter values for successful models."
      ],
      "metadata": {
        "id": "cKvcXhZj_zF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's difficult to assess the effectiveness of the models with just one epoch of training. Typically, models require multiple epochs of training to converge to an optimal solution. However, due to the computational limits I have avoided using too many epochs.\n",
        "\n",
        "All models performed similarly on test scores, making it difficult to determine which models performed better. However, it is critical to highlight the relevant hyperparameters for successful models. \n",
        "\n",
        "The relevant hyperparameters for model 1 were doubling the number of filters in each convolutional layer, adding L2 regularization to all convolutional layers, increasing the dropout rate to 0.3 in the final dense layer, changing the optimizer to Adamax with a learning rate of 0.001, and increasing the number of epochs from 1 to 10.\n",
        "\n",
        "Transfer learning from pre-trained models was used for models 2, 3, 5, and 6. Model 5 used mixed precision training to accelerate training on Tensor Core-equipped GPUs. It used global average pooling after the convolutional layers, which can reduce the number of parameters and improve performance. The batch size of 32 was specified by model 5 as a good compromise between training speed and model performance. It also added a Dense layer with 128 units directly after the VGG16 model's output. By using the steps per execution argument with a value of 16, model 5 improved performance by processing multiple batches of data in a single forward and backward pass. Finally, model 5 used the early stopping callback to avoid overfitting and accelerate training by terminating training after 5 epochs if the validation loss did not improve. However, because the model only uses one epoch, the callback function is not used.\n",
        "\n",
        "Differences in optimizers, dropout layers, and frozen layers were relevant hyperparameters that impacted model performance and generalization on the test set for models 3 and 6. Model 3 trained all layers, whereas Model 6 stopped training all but the last five layers in the base model. Model 3 used the default Adam optimizer, whereas Model 6 used the AdamW optimizer with a customized learning rate and weight decay, as well as a loss weight for the classification loss. Model 6 also included a dropout layer with a probability of 0.5 after the dense layer with 128 units. Model 3, on the other hand, did not have a dropout layer.\n",
        "\n",
        "Increasing the number of filters in convolutional layers, adding L2 regularization to prevent overfitting, changing the optimizer and learning rate, using transfer learning with pre-trained models, employing global average pooling, specifying a batch size, adding dropout layers, and freezing layers in the base model were all relevant hyperparameters for successful models."
      ],
      "metadata": {
        "id": "_PZo2zOFD1Ex"
      }
    }
  ]
}
